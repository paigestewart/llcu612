{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hello! \n",
    "In this notebook I'll try to count certain words and see their contexts in an effort to practice and understand python, and figure out what's up with Jane Austen! \n",
    "\n",
    "Below, I import os and specify my directory as the Austen file on my computer. I assign the path to the variable path so it is easier to look at (and easier for you to change!). I will show the listdir to ensure I have all the right texts in there. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1790 Love And Freindship.txt',\n",
       " '1805 Lady Susan.txt',\n",
       " '1811 Sense and Sensibility.txt',\n",
       " '1813 Pride and Prejudice.txt',\n",
       " '1814 Mansfield Park.txt',\n",
       " '1815 Emma.txt',\n",
       " '1818 Northanger Abbey.txt',\n",
       " '1818 Persuasion.txt']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "path = \"C:\\\\Users\\\\paige\\\\OneDrive\\\\Documents\\\\Applications\\\\GitHub\\\\llcu612\\\\austen\"\n",
    "os.chdir(path)\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will now import glob, open each file in the path and read it (as specified by 'r'). The loop will open each file, read it, note the name and length, then move to the next file until all files are exhausted. \n",
    "\n",
    "It should do this but... unicodeDecodeError. Not sure how to get around this. I will work with the four texts this code has been able to read.\n",
    "\n",
    "Also, I could start the filename at the number or before the space by using regular expressions, but I've been doing this code for a long time already ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paige\\OneDrive\\Documents\\Applications\\GitHub\\llcu612\\austen\\1790 Love And Freindship.txt\n",
      "184984\n",
      "C:\\Users\\paige\\OneDrive\\Documents\\Applications\\GitHub\\llcu612\\austen\\1805 Lady Susan.txt\n",
      "127290\n",
      "C:\\Users\\paige\\OneDrive\\Documents\\Applications\\GitHub\\llcu612\\austen\\1811 Sense and Sensibility.txt\n",
      "673687\n",
      "C:\\Users\\paige\\OneDrive\\Documents\\Applications\\GitHub\\llcu612\\austen\\1813 Pride and Prejudice.txt\n",
      "684768\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'charmap' codec can't decode byte 0x81 in position 890567: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-109-904db0d2a811>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'*.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m   \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\encodings\\cp1252.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcharmap_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdecoding_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mStreamWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCodec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStreamWriter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'charmap' codec can't decode byte 0x81 in position 890567: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "for filename in glob.glob(os.path.join(path, '*.txt')):\n",
    "  with open(filename, 'r') as f:\n",
    "    text = f.read()\n",
    "    print (filename)\n",
    "    print (len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will print the number of \"love\" and \"like\" instances in the four texts below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Occurrences of 'love': 122\n"
     ]
    }
   ],
   "source": [
    "print(\"Occurrences of 'love':\", text.count(\"love\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Occurrences of 'like': 222\n"
     ]
    }
   ],
   "source": [
    "print(\"Occurrences of 'like':\", text.count(\"like\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I will return the five words on either side of the word \"wonder\" using regular expressions. I could use \"love,\" in an effort to see if gender is associated with the word, but then I would return a lot more lines than with \"wonder.\" We'll borrow \"wonder\" from the last question asked in the assignment (thinking words)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['is _that_ which makes the wonder. With _your_\\ngood sense, to ',\n",
       "  'excuse for it. One cannot wonder that so\\nvery fine a ',\n",
       "  'dear Miss Eliza,\\nwe cannot wonder at his complaisance--for who would ',\n",
       "  'the officers!\" cried Lydia. \"I wonder my aunt did not tell ',\n",
       "  'six accomplished women.\\nI rather wonder now at your knowing _any_.\"\\n\\n\"',\n",
       "  'in the same way. I wonder who first\\ndiscovered the efficacy ',\n",
       "  'only shook his head.\\n\\n\"I wonder,\" said he, at the next ',\n",
       "  'cried Elizabeth. \"How abominable! I wonder that the very\\npride of ',\n",
       "  'insolent\\nthing, indeed, and I wonder how he could presume to ',\n",
       "  'was eyeing him\\nwith unrestrained wonder, and when at last Mr. ',\n",
       "  'any other person. Elizabeth would wonder,\\nand probably would blame her; ',\n",
       "  'they have known me; no wonder if they love\\nher better. ',\n",
       "  'Mrs. Bennet still continued to wonder and repine at his returning ',\n",
       "  'and\\namiable. I cannot but wonder, however, at her having any ',\n",
       "  'repentance, and rather looked with wonder at\\nher friend that she ',\n",
       "  'lane, in\\nquest of this wonder; It was two ladies stopping ',\n",
       "  'someone at his disposal. I wonder he does not marry, to ',\n",
       "  'and, to her still increasing wonder,\\nperceived an envelope containing two ',\n",
       "  'your inclination.\\n\\n\"You may possibly wonder why all this was not ',\n",
       "  'the housekeeper, had leisure to\\nwonder at her being where she ',\n",
       "  'her a look expressive of wonder.\\nElizabeth said nothing, but it ',\n",
       "  \"but think, and think with wonder, of Mr. Darcy's civility, and, \",\n",
       "  'matter of\\nconfidence, one cannot wonder. I am truly glad, dearest ',\n",
       "  'deepest disgrace. She could neither\\nwonder nor condemn, but the belief ',\n",
       "  'a connection she could not wonder that he would shrink. The\\n',\n",
       "  'each other\\nseveral times. I wonder what he can be doing ',\n",
       "  'drawing up too, and I wonder how he came to\\nmake ',\n",
       "  'with me, which I cannot wonder at, since he might have\\n',\n",
       "  'with astonishment and disdain, \"I wonder you took the trouble of ',\n",
       "  'she could do nothing but\\nwonder at such a want of ',\n",
       "  'Bingley and Jane!\" was a wonder which\\nintroduced the discussion of ',\n",
       "  'get up, sit down again, wonder, and bless herself.\\n\\n\"Good gracious! ',\n",
       "  'to admit it! But I wonder how long you\\n_would_ have ',\n",
       "  'been left to yourself. I wonder when\\nyou _would_ have spoken, ']]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "neighborsRe = []\n",
    "searchInContextRe = text\n",
    "neighborsRe.append(re.findall(r\"(?:[a-zA-Z'-]+[^a-zA-Z'-]+){0,5}wonder(?:[^a-zA-Z'-]+|$)(?:[a-zA-Z'-]+[^a-zA-Z'-]*){0,5}\", searchInContextRe))\n",
    "neighborsRe[0:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reflections\n",
    "\n",
    "I did this assignment with the Macbeth text first because I did not yet understand switching file directories. I stupidly thought once I did figure that out I could merely plug in another URL. Nope. (Well, actually, the regular expression code worked!)\n",
    "\n",
    "I feel a bit sad about this code because of that one UnicodeDecodeError thing. I also feel sad about this code because I've been trying for a very long time (15 hours? Lol) and I finally got it work so I didn't wanna fiddle too much. But, this means that I am not splitting the text on \"\\r\\n\" to remove pesky and ugly unicode markers, then joining it again. I did this with Macbeth and it was so pretty. (I also wonder if this is a smart thing to do with the sheer amount of text in the Austen Corpus.) I do feel like a learned a lot through this process. Thank goodness for this snow day!\n",
    "\n",
    "A fun thing to try once my brain turns back on would be to count a word in each text individually, rather than all the texts combined. I suppose it would mean a loop that goes over each text, then prints a few things about it (title, number), then moves onto the next one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
